{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Stroke prediction\r\n",
    "## This dataset is used to predict whether a patient is likely to get stroke based on the input parameters\r\n",
    "## Attribute Information\r\n",
    "1) **id**: unique identifier\r\n",
    "2) **gender**: \"Male\", \"Female\" or \"Other\"\r\n",
    "3) **age**: age of the patient\r\n",
    "4) **hypertension**: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\r\n",
    "5) **heart_disease**: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\r\n",
    "6) **ever_married**: \"No\" or \"Yes\"\r\n",
    "7) **work_type**: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\r\n",
    "8) **Residence_type**: \"Rural\" or \"Urban\"\r\n",
    "9) **avg_glucose_level**: average glucose level in blood\r\n",
    "10) **bmi**: body mass index\r\n",
    "11) **smoking_status**: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\r\n",
    "12) **stroke**: 1 if the patient had a stroke or 0 if not\r\n",
    "*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "# Original dataset\r\n",
    "df_orig = pd.read_csv('W:\\Downloads\\datasets\\healthcare-dataset-stroke-data.csv', index_col='id')\r\n",
    "y = df_orig['stroke'].copy()\r\n",
    "X_orig = df_orig.drop(columns=['stroke'], inplace=False)\r\n",
    "num_feat = len(X_orig.columns) \r\n",
    "num_obj = len(X_orig)\r\n",
    "# Кросс-валидация\r\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\r\n",
    "#X_orig.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def ohe(df, feature):\r\n",
    "    \"\"\"\r\n",
    "    one-hot enccoder\r\n",
    "    \"\"\"\r\n",
    "    categ_list = df[feature].unique()\r\n",
    "    df_enc = np.zeros((df.shape[0], len(categ_list)))\r\n",
    "    for ii in range(len(categ_list)):\r\n",
    "        df_enc[:, ii] = (df[feature]==categ_list[ii]).astype(int) \r\n",
    "\r\n",
    "    df_enc = pd.DataFrame(data=df_enc, index=df.index, columns=categ_list)\r\n",
    "    df_enc = pd.concat([df, df_enc], axis=1)\r\n",
    "    return df_enc\r\n",
    "\r\n",
    "# Добавление возрастных групп\r\n",
    "age_group = np.zeros(num_obj)\r\n",
    "for ii in range(num_obj):\r\n",
    "    if X_orig['age'][X_orig['age'].index[ii]] < 25:\r\n",
    "        age_group[ii] = 0\r\n",
    "    elif X_orig['age'][X_orig['age'].index[ii]] < 45:\r\n",
    "        age_group[ii] = 1\r\n",
    "    elif X_orig['age'][X_orig['age'].index[ii]] < 61:\r\n",
    "        age_group[ii] = 2\r\n",
    "    else:\r\n",
    "        age_group[ii] = 3\r\n",
    "age_group = pd.Series(data=age_group, index=X_orig.index, name='age_group')\r\n",
    "X_orig = pd.concat([X_orig, age_group], axis=1)\r\n",
    "\r\n",
    "X_prep = X_orig.copy()\r\n",
    "# Закодируем категориальные признаки\r\n",
    "# Male - 1, Female - 0\r\n",
    "X_prep['gender'] = X_prep['gender'].map({'Male': 1, 'Female': 0, 'Other': 1})\r\n",
    "# urban - 1, rural - 0\r\n",
    "X_prep['Residence_type'] = X_prep['Residence_type'].map({'Urban': 1, 'Rural': 0})\r\n",
    "# ever_married yes - 1, no - 0\r\n",
    "X_prep['ever_married'] = X_prep['ever_married'].map({'Yes': 1, 'No': 0})\r\n",
    "# work-type (one-hot (dummy) encoder)\r\n",
    "X_prep = ohe(X_prep, 'work_type')\r\n",
    "X_prep.drop(columns='work_type', inplace=True)\r\n",
    "# То же для smoking_status\r\n",
    "X_prep = ohe(X_prep, 'smoking_status')\r\n",
    "X_prep.drop(columns='smoking_status', inplace=True)\r\n",
    "# Заполним пропуски в BMI\r\n",
    "X_prep['bmi'].fillna(X_prep['bmi'].median(), inplace=True)\r\n",
    "# Age group\r\n",
    "X_prep = ohe(X_prep, 'age_group')\r\n",
    "X_prep.drop(columns='age_group', inplace=True)\r\n",
    "# Отмасштабируем\r\n",
    "scaler = StandardScaler()\r\n",
    "X_prep = pd.DataFrame(data=scaler.fit_transform(X_prep), index=X_prep.index, columns=X_prep.columns)\r\n",
    "\r\n",
    "# X_prep.drop(columns='Residence_type', inplace=True)\r\n",
    "# X_prep.drop(columns='gender', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "C_regul = [0.1]\r\n",
    "for regul in C_regul:\r\n",
    "    clf = LogisticRegression(penalty='l2', C=0.1).fit(X_prep, y)\r\n",
    "    print(cross_val_score(clf, X_prep, y, cv=cv, scoring='roc_auc').mean())\r\n",
    "# Отложенная выборка\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_prep, y, test_size=0.3)\r\n",
    "clf = LogisticRegression(penalty='l2', C=0.1).fit(X_train, y_train)\r\n",
    "#roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\r\n",
    "cross_val_score(clf, X_test, y_test, cv=cv, scoring='roc_auc')\r\n",
    "# Значимость признаков\r\n",
    "# feat_val = pd.DataFrame(data=np.abs(clf.coef_)[0], index=X_prep.columns)\r\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\r\n",
    "# feat_val.plot.bar(ax=ax)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) Support Vector Machine (SVM)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Найдем лучшие параметры"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find the best value for C regularization parameter\r\n",
    "grid_linear = {'C': [0.0001]}\r\n",
    "grid_poly = {'C': [0.01, 0.1, 1], 'gamma': [0.001, 0.01, 0.1], 'coef0': [3, 4]}\r\n",
    "grid_rbf = {'C': [0.1, 1], 'gamma': [0.001, 0.01, 0.1]}\r\n",
    "grid_sigmoid = {'C': [0.001, 0.01, 0.1], 'gamma': [0.0001, 0.01], 'coef0': [1, 10]}\r\n",
    "grids = [grid_linear, grid_poly, grid_rbf, grid_sigmoid]\r\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\r\n",
    "params = []\r\n",
    "scores = []\r\n",
    "for ind, kern in enumerate(kernels):\r\n",
    "    svc_clf = SVC(kernel=kern)\r\n",
    "    gs = GridSearchCV(estimator=svc_clf, param_grid=grids[ind], cv=cv, scoring='roc_auc')\r\n",
    "    gs.fit(X_prep, y)\r\n",
    "    params.append(gs.best_params_)\r\n",
    "    scores.append(gs.best_score_)\r\n",
    "    print(kern, gs.best_params_, gs.best_score_)\r\n",
    "params_best = params[np.argmax(scores)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим на лучших параметрах"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf_svm = SVC(C=params_best['C'], kernel='rbf', gamma=params_best['gamma'], coef0=params_best['coef0'])\r\n",
    "clf_svm.fit(X_prep, y)\r\n",
    "# Отложенная выборка\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_prep, y, test_size=0.3, random_state=42)\r\n",
    "clf_svm = SVC(C=params_best['C'], kernel='sigmoid', coef0=10).fit(X_train, y_train)\r\n",
    "np.mean(cross_val_score(clf_svm, X_test, y_test, cv=cv, scoring='roc_auc'))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_tree = X_orig.copy()\r\n",
    "# Закодируем категориальные признаки\r\n",
    "# Male - 1, Female - 0\r\n",
    "X_tree['gender'] = X_tree['gender'].map({'Male': 1, 'Female': 0, 'Other': 1})\r\n",
    "# urban - 1, rural - 0\r\n",
    "X_tree['Residence_type'] = X_tree['Residence_type'].map({'Urban': 1, 'Rural': 0})\r\n",
    "# ever_married yes - 1, no - 0\r\n",
    "X_tree['ever_married'] = X_tree['ever_married'].map({'Yes': 1, 'No': 0})\r\n",
    "# work-type (one-hot (dummy) encoder)\r\n",
    "X_tree = ohe(X_tree, 'work_type')\r\n",
    "X_tree.drop(columns='work_type', inplace=True)\r\n",
    "# То же для smoking_status\r\n",
    "X_tree = ohe(X_tree, 'smoking_status')\r\n",
    "X_tree.drop(columns='smoking_status', inplace=True)\r\n",
    "# Заполним пропуски в BMI\r\n",
    "X_tree['bmi'].fillna(X_tree['bmi'].median(), inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf_tree = DecisionTreeClassifier(criterion='entropy', ccp_alpha=0.003)\r\n",
    "clf_tree.fit(X_tree, y)\r\n",
    "\r\n",
    "print(cross_val_score(clf_tree, X_tree, y, cv=cv, scoring='roc_auc').mean())\r\n",
    "clf_tree.feature_importances_\r\n",
    "\r\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\r\n",
    "# tree.plot_tree(clf_tree, max_depth=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4) K Nearest Neighbour"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "grid = {'n_neighbors': np.arange(1, 10, dtype=int), 'p': np.arange(1, 10, dtype=int)}\r\n",
    "\r\n",
    "clf_knn = KNeighborsClassifier(weights='distance', metric='minkowski')\r\n",
    "gs = GridSearchCV(estimator=clf_knn, param_grid=grid, cv=cv, scoring='roc_auc')\r\n",
    "gs.fit(X_prep, y)\r\n",
    "print(gs.best_params_, gs.best_score_)\r\n",
    "# лучшее n = 9, p = 3"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_neighbors': 9, 'p': 3} 0.6845260145255814\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5) Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 6))\r\n",
    "# Глюкоза\r\n",
    "sns.histplot(X_orig['avg_glucose_level'], ax=ax[0, 0], kde=True)\r\n",
    "# bmi glucose\r\n",
    "sns.scatterplot(x=X_orig['avg_glucose_level'], y=X_orig['bmi'], ax=ax[1, 0])\r\n",
    "# Stroke\r\n",
    "ax[0, 1].pie(y.value_counts(), labels=['1', '0'], autopct='%.2f')\r\n",
    "# Посмотрим как зависит stroke от gender. Надо смотреть долю, т.к. М и Ж разное кол-во в выборке \r\n",
    "gender_stroke = X_orig['gender'].loc[y==1]\r\n",
    "sns.countplot(x=gender_stroke, ax=ax[1, 1])\r\n",
    "print(gender_stroke.value_counts()['Female']/X_orig['gender'].value_counts()['Female'], \r\n",
    "        gender_stroke.value_counts()['Male']/X_orig['gender'].value_counts()['Male'])\r\n",
    "# Smoking status\r\n",
    "fig1, ax1 = plt.subplots(2, 2, figsize=(10, 6))\r\n",
    "sns.countplot(y=X_orig['smoking_status'], ax=ax1[0, 0], hue=y)\r\n",
    "# Stroke от age\r\n",
    "age_stroke = X_orig['age'].loc[y==1]\r\n",
    "sns.histplot(x=age_stroke, ax=ax1[1, 0], bins=40, kde=True)\r\n",
    "ax1[1, 0].set_ylabel('Number of strokes')\r\n",
    "# Распределение возрастов\r\n",
    "sns.histplot(x=X_orig['age'], ax=ax1[0, 1], hue=X_orig['gender'], element='step', legend=True)\r\n",
    "# BMI\r\n",
    "sns.distplot(x=X_orig['bmi'], ax=ax1[1, 1])\r\n",
    "sns.distplot(x=X_orig['bmi'].loc[y==1], ax=ax1[1, 1])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "age_stroke = X_orig['age'].loc[y==1]\r\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\r\n",
    "sns.distplot(X_orig['age'], ax=ax)\r\n",
    "sns.distplot(x=age_stroke, ax=ax, bins=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.histplot(data=X_orig['age_group'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Идеи\r\n",
    "- precision-recall curve\r\n",
    "- Группы возрастов\r\n",
    "- stroke от smoke\r\n",
    "- Разные метрики качества\r\n",
    "- SVM разные ядра"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Вопросы\r\n",
    "- SVM AUC-ROC почему 0.65 всего"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "3fa3a2a7590b3915ab17662d71834416bd3a1b2d99481e19a256b8ec08b40195"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}